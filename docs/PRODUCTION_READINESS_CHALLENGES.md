# Production Readiness: Real-World Challenges & Solutions

**Last Updated:** 2025-11-29

## Executive Summary

The composable task library architecture is **powerful but non-trivial** to execute in production. This document outlines real challenges companies face when deploying workflow orchestration at scale, lessons learned from Netflix/Uber/Airbnb, and critical success factors.

**TL;DR:** This CAN work and provides massive competitive advantage, but requires disciplined execution on versioning, discovery, and organizational design.

---

## Why This Architecture Matters

### The Value Proposition

**Traditional Approach:**
- 20 teams √ó 10 integrations = 200 implementations
- Copy-paste across services
- Inconsistent patterns
- Update provider ‚Üí touch 30 codebases

**Task Library Approach:**
- 30 reusable tasks √ó 6-7 teams = 30 implementations
- **85% reduction in duplication**
- Consistent, battle-tested patterns
- Update once ‚Üí 50 workflows auto-upgrade

### The Hidden Gem: Product-to-Product Sharing

Beyond platform‚Üíproduct flow, this enables **horizontal sharing**:

**Example:**
- Pricing team builds `calculate-dynamic-pricing` task (6 months of ML work)
- Subscriptions team discovers it in catalog ‚Üí reuses it
- Marketplace team finds it ‚Üí reuses it
- Finance team uses it for revenue forecasting

**Result:** 6 months of work ‚Üí 4 teams benefit = **24 months of engineering time saved**

This creates an **internal marketplace for domain expertise** where innovation spreads organically.

---

## Critical Production Challenges

### 1. Task Versioning & Breaking Changes üî¥ CRITICAL

#### The Problem

```yaml
# Version 1: charge-payment task
inputSchema:
  properties:
    amount: { type: number }
    customerId: { type: string }

# Version 2: Add required field
inputSchema:
  properties:
    amount: { type: number }
    customerId: { type: string }
    idempotencyKey: { type: string, required: true }  # ‚Üê BREAKS 50 WORKFLOWS
```

**Impact:** Single task change breaks 50 workflows simultaneously

#### Solutions Required

**Semantic Versioning:**
```yaml
# Explicit versioning in task names
metadata:
  name: charge-payment-v2
  labels:
    version: "2.0.0"
    major-version: "2"
  annotations:
    deprecated: "false"
    successor: ""
```

**Deprecation Workflow:**
```yaml
# Mark v1 as deprecated
metadata:
  name: charge-payment-v1
  annotations:
    deprecated: "true"
    deprecation-date: "2025-12-01"
    successor: "charge-payment-v2"
    migration-guide: "https://wiki.company.com/migrate-payment-v1-v2"
```

**Workflow Pinning:**
```yaml
# Workflows can pin to specific versions
tasks:
  - taskRef: charge-payment-v2  # Explicit version
  - taskRef: charge-payment     # Latest (auto-upgrade)
```

**Migration Path:**
- Announce deprecation 90 days in advance
- Provide migration guide with code examples
- Auto-generate PR for simple migrations
- Monitor adoption of new version
- Remove old version only when usage = 0

#### Best Practices

- **Backward compatibility first:** Add optional fields, never required
- **Version early:** Start with v1, not "charge-payment"
- **Communicate changes:** Slack alerts when tasks change
- **Gradual rollout:** Canary 5% ‚Üí 25% ‚Üí 50% ‚Üí 100%

---

### 2. Single Point of Failure √ó 50 üî¥ CRITICAL

#### The Problem

```
Buggy task deployment ‚Üí 50 workflows fail
Performance regression ‚Üí Cascading slowness across org
Typo in YAML ‚Üí Customer-facing errors
```

**Blast radius is exponentially larger than microservice failures.**

#### Solutions Required

**Canary Deployments:**
```yaml
# Deploy to 5% of workflows first
apiVersion: workflow.io/v1
kind: WorkflowTask
metadata:
  name: charge-payment-v2
  annotations:
    rollout-strategy: "canary"
    canary-percentage: "5"
```

**Circuit Breakers:**
```typescript
// Auto-disable failing tasks
if (taskErrorRate > 50% && requestCount > 100) {
  disableTask(taskName);
  alertOwners();
  rollbackToLastVersion();
}
```

**Staging Environment:**
- Dedicated staging namespace for task testing
- Require staging validation before production
- Load testing for performance regressions

**High Test Coverage:**
- Maintain >90% code coverage (already achieved)
- Mutation testing for quality validation
- Contract testing for interface stability

**Monitoring & Alerting:**
```yaml
# Per-task SLAs
sla:
  error-rate: < 1%
  p95-latency: < 500ms
  availability: > 99.9%

alerts:
  - error-rate > 5% for 5 minutes ‚Üí Page owner
  - latency > 1s for 10 minutes ‚Üí Slack alert
  - availability < 99% ‚Üí Executive escalation
```

#### Organizational Requirements

- **On-call rotation** for critical tasks (payments, auth)
- **Runbook** for each task (how to debug, rollback)
- **Incident response** process (who, what, when)
- **Post-mortems** for all task failures

---

### 3. Task Discovery Fails at Scale üü° IMPORTANT

#### The Problem

```
Month 1: 10 tasks ‚Üí Easy to browse
Month 6: 100 tasks ‚Üí Becoming cluttered
Month 12: 500+ tasks ‚Üí Impossible to find anything

Result: Teams build duplicate tasks, defeating the purpose
```

**Example:** 5 variations of "send-email" task because teams couldn't find the canonical one.

#### Solutions Required

**Task Catalog UI (Stage 9.2 - NON-NEGOTIABLE):**

Must have:
- **Search with relevance ranking**
- **Category filtering** (payments, ml, notifications, data)
- **Tag-based organization** (async, realtime, batch)
- **Sort by:** Most used, Trending, Recently updated, Rating
- **Task details page:** Description, input/output schemas, examples, metrics

**Rich Metadata:**
```yaml
metadata:
  name: calculate-dynamic-pricing
  annotations:
    owner: "pricing-team@company.com"
    category: "pricing, ml, recommendations"
    tags: "machine-learning, real-time, experimental"
    difficulty: "advanced"
    use-cases: "e-commerce, subscriptions, marketplace"
    documentation: "https://wiki.company.com/tasks/dynamic-pricing"

status:
  usageCount: 23
  successRate: 98.5%
  avgDuration: "120ms"
  consumers:
    - order-fulfillment
    - subscription-renewal
    - marketplace-pricing
```

**Discovery Features:**
- **"Most used" list:** Show popular tasks (social proof)
- **"Trending" list:** Recently adopted tasks (FOMO effect)
- **Recommendations:** "Teams using X also use Y"
- **Similar tasks:** "charge-payment-stripe vs charge-payment-braintree"
- **Example workflows:** See tasks in action

**Quality Signals:**
- **Star rating** (from consumers)
- **Success rate** (reliability metric)
- **Usage count** (popularity)
- **Owner responsiveness** (avg time to fix issues)

#### Preventing Task Sprawl

**Encourage consolidation:**
- Before creating new task, search for similar ones
- Suggest parameterization over duplication
- Quarterly task review: Retire/archive unused tasks
- Merge similar tasks with approval

---

### 4. Platform Team Becomes Bottleneck üü° IMPORTANT

#### The Problem

```
Product team: "We need task for X"
Platform team: "We'll prioritize it in Q3" (3 months away)
Product team: *builds their own anyway*
Result: Fragmentation, parallel implementations, defeat purpose
```

#### Solution: Federated Ownership

**NOT THIS (Centralized):**
```
All tasks ‚Üí Platform team reviews ‚Üí Approves ‚Üí Deploys
```

**THIS (Federated):**
```
Teams create tasks ‚Üí Auto-validation ‚Üí Self-service deploy ‚Üí Platform team curates
```

**Ownership Model:**
```yaml
# Each team owns their domain tasks
metadata:
  name: calculate-dynamic-pricing
  annotations:
    owner: "pricing-team@company.com"
    approvers: "platform-team@company.com"  # Only for critical tasks
    auto-deploy: "true"  # No manual approval needed
```

**Platform Team Role:**
- **Curator, not gatekeeper:** Review quality, don't block
- **Tooling provider:** Build task scaffolding, validation, CI/CD
- **Standards enforcer:** Ensure >90% test coverage, docs, schemas
- **Support:** Help teams build better tasks

**Self-Service with Guardrails:**
```bash
# CLI for creating new tasks
$ workflow-cli task create --name my-task --template http

‚úÖ Generated task scaffold
‚úÖ Added test template
‚úÖ Configured CI/CD
‚úÖ Registered in catalog

Next steps:
1. Implement task logic in src/my-task.yaml
2. Add tests in tests/my-task.test.ts
3. Run: workflow-cli task validate
4. Deploy: workflow-cli task deploy --canary
```

**Automated Quality Gates:**
- ‚úÖ Schema validation (input/output defined)
- ‚úÖ Test coverage >90%
- ‚úÖ Documentation present
- ‚úÖ No secrets in YAML
- ‚úÖ Performance benchmarks pass

**Clear SLAs:**
- Task review: Within 2 business days
- Bug fixes: P0 (24h), P1 (1 week), P2 (2 weeks)
- Feature requests: Triaged in monthly planning

---

### 5. Testing Workflows with Task Dependencies üü° IMPORTANT

#### The Problem

```yaml
# How do you test this workflow locally without calling real APIs?
tasks:
  - taskRef: charge-payment  # ‚Üê Calls real Stripe API
  - taskRef: send-email      # ‚Üê Sends real emails
  - taskRef: fetch-user      # ‚Üê Queries production database
```

**Impact:** Slow tests, flaky CI/CD, accidental API calls in test runs

#### Solutions Required

**1. Task Mocking:**
```typescript
// Test mode: Override tasks with mocks
const mockTasks = {
  'charge-payment': async (input) => ({
    success: true,
    transactionId: 'mock-txn-123',
    status: 'succeeded'
  }),
  'send-email': async (input) => ({
    success: true,
    messageId: 'mock-msg-456'
  })
};

await orchestrator.executeAsync(workflow, mockTasks, inputs);
```

**2. Stub Tasks:**
```yaml
# Create test-only stub versions
apiVersion: workflow.io/v1
kind: WorkflowTask
metadata:
  name: charge-payment-stub
  namespace: test
spec:
  type: transform
  transform:
    # Returns fake data immediately
    output:
      transactionId: "stub-txn-{{input.customerId}}"
      status: "succeeded"
```

**3. Test Environments:**
```yaml
# Isolated task instances per environment
environments:
  - name: production
    taskNamespace: default
  - name: staging
    taskNamespace: staging
  - name: test
    taskNamespace: test
    stubTasks: true  # Use stubs by default
```

**4. Contract Testing:**
```typescript
// Validate task interface without execution
test('charge-payment contract', async () => {
  const task = await getTask('charge-payment');

  // Input schema validation
  expect(task.inputSchema).toMatchSchema({
    type: 'object',
    required: ['amount', 'customerId']
  });

  // Output schema validation
  expect(task.outputSchema).toMatchSchema({
    type: 'object',
    required: ['transactionId', 'status']
  });
});
```

---

### 6. Monitoring & Debugging Complexity üü° IMPORTANT

#### The Problem

```
Workflow "order-fulfillment" failed at 10:23 AM
- Which task failed?
- Why did it fail?
- What was the input?
- Where are the logs?
- Was it a transient error or permanent?
- Did retries happen?
```

**Debugging distributed workflows is exponentially harder than debugging monoliths.**

#### Solutions Already Built

‚úÖ **Execution Traces (Stage 7.9):**
- Per-task start/end timestamps
- Wait time calculation
- Dependency resolution tracking
- Parallel execution detection

#### Additional Requirements

**Distributed Tracing:**
```typescript
// Correlation IDs across task executions
const executionId = generateId();
const trace = {
  executionId,
  workflowName: 'order-fulfillment',
  userId: 'user-123',
  tasks: [
    {
      taskId: 'task1',
      taskRef: 'charge-payment',
      startTime: '2025-11-29T10:23:01Z',
      endTime: '2025-11-29T10:23:03Z',
      duration: '2s',
      status: 'succeeded',
      traceId: executionId  // ‚Üê Propagated to downstream services
    }
  ]
};
```

**Per-Task Metrics:**
```yaml
# Expose task-level metrics
metrics:
  charge-payment:
    requests-per-second: 45
    p50-latency: 120ms
    p95-latency: 450ms
    p99-latency: 890ms
    error-rate: 0.8%
    success-rate: 99.2%

    errors:
      - type: "payment-declined"
        count: 23
        percentage: 60%
      - type: "timeout"
        count: 8
        percentage: 20%
```

**Error Attribution:**
```json
{
  "executionId": "exec-123",
  "workflowName": "order-fulfillment",
  "status": "failed",
  "failedTask": {
    "taskId": "charge-customer",
    "taskRef": "charge-payment",
    "error": {
      "type": "PaymentDeclinedError",
      "message": "Insufficient funds",
      "httpStatus": 402,
      "retryable": false
    }
  }
}
```

**Log Aggregation:**
- Centralized logging (CloudWatch, Splunk, DataDog)
- Structured logs with executionId
- Log retention policy (90 days)

---

### 7. Secret Management üü† MODERATE

#### The Problem

```yaml
# Task needs API keys - how are they secured?
http:
  headers:
    Authorization: "Bearer {{env.STRIPE_API_KEY}}"
```

**Security requirements:**
- Secrets encrypted at rest
- Access controlled (only payment tasks can access payment secrets)
- Audit logging (who accessed what, when)
- Rotation without breaking workflows

#### Solutions Required

**Kubernetes Secrets:**
```yaml
apiVersion: v1
kind: Secret
metadata:
  name: stripe-api-key
  namespace: default
type: Opaque
data:
  key: <base64-encoded-secret>
```

**Secret References in Tasks:**
```yaml
http:
  headers:
    Authorization: "Bearer {{secrets.stripe-api-key}}"
```

**RBAC:**
```yaml
# Only tasks in "payments" namespace can access payment secrets
kind: Role
metadata:
  namespace: payments
rules:
  - apiGroups: [""]
    resources: ["secrets"]
    resourceNames: ["stripe-api-key"]
    verbs: ["get"]
```

**Secret Rotation:**
```bash
# Rotate secret without downtime
$ kubectl create secret generic stripe-api-key-v2 --from-literal=key=<new-key>
$ kubectl patch task charge-payment --patch '{"spec": {"secretRef": "stripe-api-key-v2"}}'
$ kubectl delete secret stripe-api-key  # After grace period
```

---

### 8. Performance & Rate Limiting üü† MODERATE

#### The Problem

```
1000 workflows execute simultaneously
All call "fetch-user" task
User service receives 1000 req/s
User service dies
```

**High concurrency requires infrastructure thinking.**

#### Solutions Required

**Rate Limiting:**
```yaml
spec:
  rateLimit:
    requestsPerSecond: 100
    burstSize: 200
    backoffStrategy: "exponential"
```

**Caching:**
```yaml
spec:
  cache:
    enabled: true
    ttl: "5m"
    key: "{{input.userId}}"  # Cache by user ID
```

**Load Balancing:**
```yaml
# Multiple task instances
apiVersion: v1
kind: Service
metadata:
  name: fetch-user-task
spec:
  replicas: 3
  selector:
    app: fetch-user
```

**Backpressure:**
```typescript
// Queue requests when overloaded
if (queueDepth > 1000) {
  return { status: 503, error: 'Service overloaded, retry later' };
}
```

---

### 9. Cost Attribution üü¢ NICE TO HAVE

#### The Problem

```
Cloud bill: $50,000 this month
- Which team?
- Which workflow?
- Which task?
- Which API calls are expensive?
```

**Finance will demand answers.**

#### Solutions Required

**Per-Execution Cost Tracking:**
```typescript
{
  executionId: 'exec-123',
  workflowName: 'order-fulfillment',
  team: 'e-commerce',
  costs: {
    'charge-payment': { api_calls: 1, cost: '$0.03' },
    'send-email': { api_calls: 1, cost: '$0.001' },
    total: '$0.031'
  }
}
```

**Team Labels:**
```yaml
metadata:
  name: order-fulfillment
  labels:
    team: "e-commerce"
    cost-center: "CC-12345"
    environment: "production"
```

**Budget Alerts:**
```yaml
budgets:
  - team: "marketing"
    monthly-limit: "$10,000"
    alert-threshold: 80%
    action: "notify-slack"
```

---

### 10. Organizational Challenges (Often Underestimated!)

#### Political Challenges

**Platform team doesn't want responsibility:**
- "We don't have capacity to support all tasks"
- Solution: Federated ownership

**Product teams don't trust shared services:**
- "Last time we used shared service, it went down and broke our feature"
- Solution: High reliability standards, SLAs, monitoring

**"Not Invented Here" syndrome:**
- "Our use case is special, we need our own implementation"
- Solution: Show value with metrics, executive mandate

#### Cultural Challenges

**Teams want autonomy:**
- Resist standardization
- Solution: Self-service with guardrails, not gatekeeping

**Incentives misaligned:**
- Rewarded for features shipped, not reusability
- Solution: Include "task contributions" in performance reviews

**Unclear ownership:**
- When shared task breaks, who fixes it?
- Solution: Clear ownership annotations, on-call rotations

#### Process Challenges

**Approval workflows:**
- Who approves task changes?
- Solution: Auto-approval for non-critical, manual for payments/auth

**Deprecation process:**
- How do we sunset old tasks?
- Solution: 90-day deprecation window, migration guides

**SLAs:**
- What's the uptime guarantee?
- Solution: Tiered SLAs (critical: 99.9%, standard: 99%)

#### Requirements for Success

**Executive Buy-In:**
- CTO/VP Engineering mandate: "We're building a task library, everyone participates"
- Include in quarterly OKRs
- Celebrate wins in all-hands

**Communication:**
- Slack channel: #task-library
- Monthly newsletter: New tasks, upcoming deprecations, success stories
- Quarterly review: Usage stats, ROI metrics

**Incentive Alignment:**
- Performance reviews include "reusability contributions"
- Celebrate "most-reused task" in all-hands
- Engineer of the quarter for best task contribution

---

## Why Companies Struggled Before

### Existing Solutions & Their Limitations

**1. AWS Step Functions**
- ‚úÖ Great workflow orchestration
- ‚ùå No task library concept
- ‚ùå AWS-only, not K8s native

**2. Temporal/Cadence**
- ‚úÖ Powerful workflow engine
- ‚ùå Complex (steep learning curve)
- ‚ùå Focused on long-running workflows (not API composition)

**3. Argo Workflows**
- ‚úÖ K8s native
- ‚ùå YAML-heavy, not task-focused
- ‚ùå Batch/CI focus, not API orchestration

**4. Apache Airflow**
- ‚úÖ Mature ecosystem
- ‚ùå Batch/ETL focus, not real-time
- ‚ùå Not designed for synchronous API calls

**5. Zapier/n8n**
- ‚úÖ Great UX, visual workflow builder
- ‚ùå SaaS/no-code, not enterprise-scale
- ‚ùå Limited customization

### What They Missed

**Missing pieces:**
- Task library as **first-class citizen**
- **Discoverability** (catalog, search, recommendations)
- **Federated ownership** (not centralized bottleneck)
- **Simple mental model** (Lego bricks, not complex DAGs)

### Internal Implementations

**Netflix, Uber, Airbnb built custom solutions:**
- Tailored to their specific needs
- Not open-sourced (competitive advantage)
- Didn't emphasize task reusability

**They learned these lessons the hard way.**

---

## Your Competitive Advantages

### What's Already Built ‚úÖ

**Strong Foundation:**
- ‚úÖ Execution traces (Stage 7.9) - debugging capability
- ‚úÖ Workflow versioning (Stage 7.9) - change tracking
- ‚úÖ Validation webhooks (Stage 6) - fail-fast at design time
- ‚úÖ Parallel execution (Stage 7.5) - performance
- ‚úÖ >90% test coverage - quality foundation
- ‚úÖ K8s native - fits existing infrastructure
- ‚úÖ Mutation testing - quality validation

### Critical Gaps ‚ùå

**Must build before production:**
- ‚ùå Task versioning (breaking changes will hurt)
- ‚ùå Task catalog UI (Stage 9.2) - discovery will fail
- ‚ùå Federated ownership model
- ‚ùå Task mocking for testing
- ‚ùå Canary deployments
- ‚ùå Per-task monitoring

---

## Production Readiness Roadmap

### Phase 1: Prove the Concept (1-2 months)

**Goal:** Validate value with small pilot

**Activities:**
- Build 5-10 high-value tasks (payments, email, user-fetch)
- Pilot with 1 product team
- Build 3-5 workflows using task library
- Measure: Time to ship features, developer satisfaction

**Success Metrics:**
- 3√ó faster workflow creation
- Zero duplication
- Developer NPS >8

**Decision Point:** If positive, proceed to Phase 2

---

### Phase 2: Harden Infrastructure (2-3 months)

**Goal:** Build production-grade infrastructure

**Critical Path:**

**1. Task Catalog UI (Stage 9.2) - NON-NEGOTIABLE**
- Search and filtering
- Category organization
- Usage statistics
- Example workflows
- Owner contact info

**2. Task Versioning**
- Semantic versioning in task names
- Deprecation workflow
- Migration guides
- Version pinning in workflows

**3. Monitoring & Alerting**
- Per-task metrics (latency, error rate)
- Execution traces enhancement
- Distributed tracing integration
- Alerting rules and runbooks

**4. Testing Strategy**
- Task mocking framework
- Stub tasks for testing
- Contract testing
- CI/CD integration

**5. Security**
- Secret management (K8s secrets)
- RBAC for task modifications
- Audit logging

---

### Phase 3: Scale Adoption (3-6 months)

**Goal:** Expand to 5-10 product teams

**Activities:**
- Establish federated ownership model
- Create task creation templates
- Write documentation and examples
- Train teams on best practices
- Build self-service tooling

**Success Metrics:**
- 50+ tasks in library
- 30+ workflows deployed
- 70% task reuse rate
- Platform team is NOT a bottleneck

---

### Phase 4: Production-Ready (6-12 months)

**Goal:** Company-wide rollout

**Activities:**
- SLAs for critical tasks (99.9% uptime)
- Support model (on-call rotations)
- Cost attribution and budgets
- Quarterly task review process
- Continuous improvement

**Success Metrics:**
- 100+ tasks in library
- 100+ workflows in production
- 85% duplication reduction
- 10√ó faster feature shipping

---

## Success Criteria

### Technical Metrics

- ‚úÖ Task library contains 100+ tasks
- ‚úÖ 80% task reuse rate across teams
- ‚úÖ >99% task reliability (error rate <1%)
- ‚úÖ <500ms p95 latency for task execution
- ‚úÖ >90% test coverage maintained
- ‚úÖ Zero production incidents from task failures

### Organizational Metrics

- ‚úÖ 10+ teams actively using task library
- ‚úÖ 5√ó faster workflow creation
- ‚úÖ 85% reduction in code duplication
- ‚úÖ Developer NPS >8
- ‚úÖ Platform team is enabler, not bottleneck
- ‚úÖ Cross-team task sharing happening organically

### Business Metrics

- ‚úÖ 50% reduction in time-to-market for new features
- ‚úÖ $500k+ annual savings from reduced duplication
- ‚úÖ Improved developer satisfaction
- ‚úÖ Competitive advantage in velocity

---

## Critical Success Factors

### Must Have

1. **Task Catalog UI** - Discovery is everything
2. **Task Versioning** - Breaking changes kill adoption
3. **Federated Ownership** - Platform team can't be bottleneck
4. **Executive Buy-In** - Cultural shift requires leadership
5. **Quality Standards** - >90% test coverage non-negotiable

### Nice to Have

- Cost attribution
- Advanced analytics
- Visual workflow builder
- Neural network visualization

---

## When to Abort

**Red flags that this won't work:**

‚ùå Platform team is understaffed (can't support scale)
‚ùå Executive buy-in is weak (no mandate for adoption)
‚ùå Teams actively resist (strong "not invented here" culture)
‚ùå Quality standards slip (<80% test coverage)
‚ùå Task discovery remains poor (no catalog investment)

**If you see 3+ red flags, reconsider the approach.**

---

## Conclusion

**This architecture CAN provide massive competitive advantage, but it's not simple.**

**The concept is elegant. The execution is brutal.**

**Success requires:**
- Disciplined versioning
- Great discovery (catalog UI)
- Federated ownership
- Cultural shift
- Executive mandate

**But if you execute well:**
- 10√ó faster feature shipping
- 85% reduction in duplication
- Internal marketplace for expertise
- Sustainable competitive advantage

**The question is:** Are you ready for the complexity?

---

## Next Steps

1. **Review this document with leadership** - Ensure alignment on challenges
2. **Plan Phase 1 pilot** - Pick 1 product team, build 5-10 tasks
3. **Prioritize Stage 9.2** - Task Catalog UI is non-negotiable
4. **Design versioning strategy** - Critical before scaling
5. **Establish federated ownership** - Platform team as enabler, not gatekeeper

**Good luck. You're building something powerful.**
